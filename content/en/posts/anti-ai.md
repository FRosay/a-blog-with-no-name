+++
title = "I am not anti-AI, it's AI that is anti-me"
date = '2026-02-01T19:00:00+01:00'
draft = true
+++

> Foreword: this article probably doesn't reflect what I think very well, or at least it doesn't reflect the entirety of what I think. Yet here it is, as a snapshot of my current thoughts. Although I don't believe I will disown them very soon - if ever -, they will probably keep evolving. Please keep this in mind while reading. (Also english is not my first language, so there's that too.)

The title of this article may look like a joke to you, but know that it is, in fact, not a joke. It is merely a way to somewhat summarize what would have been an honest title[^title]

However, it probably warrants some precisions before we really get going.
So let's just say that when the title says "AI", it actually means the current batch of "generative AI": [LLMs](https://en.wikipedia.org/wiki/Large_language_model) (Large Language Models, like ChatGPT). Let's also say that, because AI[^AI] doesn't have a conscience and is incapable of reasoning, it can't be "anti" anything. Lastly, please know that I do not think so highly of myself that I would believe that an AI - even an actually intelligent one - could be anti "me" personally. But I do believe that AI poses significant problems, problems we should be solving _before_ we use try push AI into every part of everyone's life.

## AI's biggest problem is that it has so many

It is immediately clear, when taking a critical look at AI, that it has many negative impacts on many different areas of many different people's life. The most discussed of those problems are probably it's ecological impact[^ecology], the fact that it replaces or devalues certain jobs, and the general plundering of data, with no respect for copyright or privacy, that sustains it. One might also think about the current debate on wether LLMs actually make us more productive or not, the fact that the whole industry was mostly built on lies[^lies], or the long-term risks on our ability to learn that AI poses, among other topics. Yet as interesting and valid as all of those subjects are, I would like to touch on a slighly different one.

As someone who regularly tries to discuss AI[^discuss] with any and all people who are willing to, I can't help but feel that most people who use LLMs mostly know about all the problems mentioned above. It just isn't enough to stop them from using their favorite chatbot. Why is that? Are we so used to hearing about our negative ecological impact that we just can't be bothered anymore? Is it the fact that we always have a hard time apprehending things we do not immediately see? Is the hope of fabulous personal gains totally eclipsing our moral sentiment?

Those questions are probably as complex when it comes to individuals as they are trivially answered when it comes to businesses, who only view profit - or potential profit even - as a desirable thing to pursue. But however complex they might be, I keep hearing the same justifications for the use of AI, and I just can't stand them anymore.

## Putting the political back in AI

During most, if not every informal conversation I have about AI, people tell me one of two things. Either that AI "is just a tool" that we must learn how to use, or that AI "is here anyways", and so we must, for some reason, adapt. Just common knowledge, really. Nothing out of the ordinary. But I strongly feel that both ways of thinking lead to an intellectual impasse.

### Tools are never just tools

What is being said (albeit maybe unknowignly) when someone says that AI is "just" a tool? What is being left aside? Well first, this is obviously ignoring the tool's existence before it is being using and everything that was necessary - materially, politically... - to even make it in the first place. Talking about AI, this is refusing to think about the whole chain of supply, from collecting rare metals in dramatic conditions to undiscriminately pillaging the internet's data, including every work of art every posted online.

Even if you can ignore the existence a tool has had before you can wield it, it would still be wrong to assume that you should limit your thinking to how it is being used. [This article](https://www.frank.computer/blog/2025/05/just-a-tool.html) by Frank Elavsky says it very well: a tool is always made for certain uses; it will inhibit others, or render them impossible. A hammer will make you hold it by the handle and hit with the head. You _can_ very much do the opposite, but you'll be far less efficient. A hammer also makes you swing it when you use it. Again, you _can_ technically just put it against a nail and push, but good luck with that.

Now let's think about another kind of tool, one where the reasoning would be more radical. A gun, for example. Now a gun clearly isn't "just" a tool. It's a killing machine, or at least a wounding or maiming machine. The very fact of carrying is gun is thus something that a lot of people, myself included, simply refuse. It is a moral stance, and one that was popular enough that entire countries would accept civil alternatives to their military services.

It should be evident, then, that such a moral position can also be held regarding other tools, including generative AI or [any other technology](https://aeon.co/essays/bernard-stieglers-philosophy-on-how-technology-shapes-our-world). Because it obviously doesn't depend on the tool itself as limited by it's physical presence, but on what the tool does, implies, or why it exists. LLMS, unlike guns, aren't literal killing machines, but they are, unfortunately for their fans, [slop](https://en.wikipedia.org/wiki/AI_slop) machines. And isn't [the purpose of a system](https://en.wikipedia.org/wiki/The_purpose_of_a_system_is_what_it_does) what it does rather than what it is supposed to do?

### 


[^title]: Such as "Yes I do have some objections to the use of AI, not because I am against technology or a contrarian, but because generative AI such as it exists today is either dangerous or, at best, doing us a disservice", for example.
[^AI]: Yes I will be writing "AI" instead of "generative AI" or "LLMs". Sorry not sorry.
[^ecology]: Yes it has a lower impact than other industries, but that doesn't make it automatically acceptable. It's still an additional weight on our global carbon footprint, which cannot be justified by the only thing it actually mass produces : _[slop](https://en.wikipedia.org/wiki/AI_slop)_.
[^lies]: We'll get back to those.
[^discuss]: Even though I can't really recommend it, to be fair.