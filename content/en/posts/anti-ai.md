+++
title = "I am not anti-AI, it's AI that is anti-me"
date = '2026-02-01T19:00:00+01:00'
draft = true
+++

> Foreword: this article probably doesn't reflect what I think very well, or at least it doesn't reflect the entirety of what I think. Yet here it is, as a snapshot of my current thoughts. Although I don't believe I will disown them very soon - if ever -, they will probably keep evolving. Please keep this in mind while reading. (Also english is not my first language, so there's that too.)

The title of this article may look like a joke to you, but know that it is, in fact, not a joke. It is merely a way to somewhat summarize what would have been an honest title[^title]

However, it probably warrants some precisions before we really get going.
So let's just say that when the title says "AI", it actually means the current batch of "generative AI": [LLMs](https://en.wikipedia.org/wiki/Large_language_model) (Large Language Models, like ChatGPT). Let's also say that, because AI[^AI] doesn't have a conscience and is incapable of reasoning, it can't be "anti" anything. Lastly, please know that I do not think so highly of myself that I would believe that an AI - even an actually intelligent one - could be anti "me" personally. But I do believe that AI poses significant problems, problems we should be solving _before_ we use try push AI into every part of everyone's life.

## AI's biggest problem is that it has so many

It is immediately clear, when taking a critical look at AI, that it has many negative impacts on many different areas of many different people's life. The most discussed of those problems are probably it's ecological impact[^ecology], the fact that it replaces or devalues certain jobs, and the general plundering of data, with no respect for copyright or privacy, that sustains it. One might also think about the current debate on wether LLMs actually make us more productive or not, the fact that the whole industry was mostly built on lies[^lies], or the long-term risks on our ability to learn that AI poses, among other topics. Yet as interesting and valid as all of those subjects are, I would like to touch on a slighly different one.

As someone who regularly tries to discuss AI[^discuss] with any and all people who are willing to, I can't help but feel that most people who use LLMs mostly know about all the problems mentioned above. It just isn't enough to stop them from using their favorite chatbot. Why is that? Are we so used to hearing about our negative ecological impact that we just can't be bothered anymore? Is it the fact that we always have a hard time apprehending things we do not immediately see? Is the hope of fabulous personal gains totally eclipsing our moral sentiment?

Those questions are probably as complex when it comes to individuals as they are trivially answered when it comes to businesses, who only view profit - or potential profit even - as a desirable thing to pursue. But however complex they might be, I keep hearing the same justifications for the use of AI, and I just can't stand them anymore.

## Putting the political back in AI

During most, if not every informal conversation I have about AI, people tell me one of two things. Either that AI "is just a tool" that we must learn how to use, or that AI "is here anyways", and so we must, for some reason, adapt. Just common knowledge, really. Nothing out of the ordinary. But I strongly feel that both ways of thinking lead to an intellectual impasse.

### Tools are never just tools

What is being said (albeit maybe unknowignly) when someone says that AI is "just" a tool? What is being left aside? Well first, this is obviously ignoring the tool's existence before it is being using and everything that was necessary - materially, politically... - to even make it in the first place. Talking about AI, this is refusing to think about the whole chain of supply, from collecting rare metals in dramatic conditions to undiscriminately pillaging the internet's data, including every work of art every posted online.

Even if you can ignore the existence a tool has had before you can wield it, it would still be wrong to assume that you should limit your thinking to how it is being used. [This article](https://www.frank.computer/blog/2025/05/just-a-tool.html) by Frank Elavsky says it very well: a tool is always made for certain uses; it will inhibit others, or render them impossible. A hammer will make you hold it by the handle and hit with the head. You _can_ very much do the opposite, but you'll be far less efficient. A hammer also makes you swing it when you use it. Again, you _can_ technically just put it against a nail and push, but good luck with that.

Now let's think about another kind of tool, one where the reasoning would be more radical. A gun, for example. Now a gun clearly isn't "just" a tool. It's a killing machine, or at least a wounding or maiming machine. The very fact of carrying is gun is thus something that a lot of people, myself included, simply refuse. It is a moral stance, and one that was popular enough that entire countries would accept civil alternatives to their military services.

It should be evident, then, that such a moral position can also be held regarding other tools, including generative AI or [any other technology](https://aeon.co/essays/bernard-stieglers-philosophy-on-how-technology-shapes-our-world). Because it obviously doesn't depend on the tool itself as limited by it's physical presence, but on what the tool does, implies, or why it exists. LLMS, unlike guns, aren't literal killing machines, but they are, unfortunately for their fans, [slop](https://en.wikipedia.org/wiki/AI_slop) machines. And isn't [the purpose of a system](https://en.wikipedia.org/wiki/The_purpose_of_a_system_is_what_it_does) what it does rather than what it is supposed to do?

### Fear of missing out on AI: but missing out on what exactly?

The other thing that I feel I'm hearing all the time is some variation on "well AI is here now anyway", the subtext being "might as well use it". "Too bad, I didn't want to use it but I guess I _have_ to". And this is something that I hear everywhere, not only from people who don't really have an opinion about AI, but also from those who are in favor or against it.

People with a bad opinion of AI will be seemingly driven more by fatalism or some kind of external pressure, but will still sometimes join with people who have a good opinion of AI into some kind of [FOMO](https://en.wikipedia.org/wiki/Fear_of_missing_out) that's barely disguised as pragmatism. Lastly, people with no particular opinion on AI seem to follow a version of the [principle of least effort](https://en.wikipedia.org/wiki/Principle_of_least_effort): everyone is doing it and I guess that it makes my Google searches faster, so I guess I'll just use it.

In any case, all of those approaches not only accept AI's _existence_, but more importantly a form of _usefulness_. However, it is still not certain that LLMs actually make us more productive. Even if they did, for certain professions or certain people, we could also decide, as a society, that the collective price to pay exceeds the current benefits we get from AI. Because let's face it: AI has all but proven to be a reliable way to improve our existence.

As for the benefits of AI[^benefits], let's start by remembering how LLMs, as products, were sold on some of the biggest lies of the last decade, which means a lot when you consider that said decade also saw the emergence of blockhain, NFTs, crypto and the metaverse. Even then, you do not have to do a lot of research to see that LLMs are almost never as useful as you're told they are, and rarely even useful at all. Most of the time, [it's not even AIs](https://em360tech.com/tech-articles/why-are-humans-pretending-be-bots-rise-pseudo-ai-tech) but [actual human beings](https://www.business-humanrights.org/en/latest-news/philippines-scale-ai-creating-race-to-the-bottom-as-outsourced-workers-face-poor-conditions-in-digital-sweatshops-incl-low-wages-withheld-payments/), a lot of them [in India](https://timesofindia.indiatimes.com/technology/tech-news/how-this-billion-dollar-london-startup-backed-by-microsoft-made-700-engineers-sitting-in-india-pose-as-ai/articleshow/121572659.cms) [^humans].

And even when we're talking about machines, it can be difficult to find scientific studies about AI's performance. To take just one example, [this reddit post](https://www.reddit.com/r/ClaudeAI/comments/1mwtyan/are_there_any_real_benchmarks_showing_these_ai/) asks about exactly this, and the only study ever mentioned in the thread is the [famous METR study](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/) from july 2025. Except it found that experienced open-source developers were less productive when using AI, not the other way around.

## Solutionism is not a solution

The first impulse when hearing about most of AIs problems, as with a lot of problems in general, is to try and find a solution. Unfortunately, any attempt at "fixing" something will depend on the diagnostic you make. Analysing a problem as contingent will probably lead to considering contingent solutions, instead of structural ones which may very well be what we need in AIs case. As Cory Doctorow puts it, "[AI is the asbestos we are shoveling into the walls of our society](https://pluralistic.net/2025/09/27/econopocalypse/#subprime-intelligence)"; if only we didn't rush to use asbestos everywhere at the time...

Meanwhile, who says that we _have_ to use a technology as nefarious as AI? It's usually not a very popular argument, but a form of technological degrowth doesn't mean being anti-technology or even anti-AI. Questioning and wanting to limit the general and unfettered use of super-chatbots is not an attack of anything. Rather, it is in defense of us humans, in trying to protect us from an emerging polluting industry. In trying to make sure that our tool do not make us [less creative](https://drive.google.com/file/d/1K3nSFdrKwg4h314skO3kT--Rso3xQ1Dd/view) or [less intelligent](https://arxiv.org/abs/2506.08872)[^intelligence] _before_ everyone uses them, not afterwards.

"_Move fast and break things_", Facebook's motto until 2014, could be a reasonable goal when you're just developing a banal website as fast a possible and intending on fixing every bug later. It definately is _not_ a reasonable goal when it means always staying one step ahead of government regulation and the things you are breaking are actual human lives. It is still time to slow down or even take a break on using AI. Let's give ourselves the times to consciously and collectively decide what we want or not. 


[^title]: Such as "Yes I do have some objections to the use of AI, not because I am against technology or a contrarian, but because generative AI such as it exists today is either dangerous or, at best, doing us a disservice", for example.
[^AI]: Yes I will be writing "AI" instead of "generative AI" or "LLMs". Sorry not sorry.
[^ecology]: Yes it has a lower impact than other industries, but that doesn't make it automatically acceptable. It's still an additional weight on our global carbon footprint, which cannot be justified by the only thing it actually mass produces : _[slop](https://en.wikipedia.org/wiki/AI_slop)_.
[^lies]: We'll get back to those.
[^discuss]: Even though I can't really recommend it, to be fair.
[^benefits]: The fact that you have to go looking for them at all is already not great. I mean, I don't remember people wondering how to make a smartphone or a laptop useful for them?
[^humans]: Other articles include the following, in no particular order: [1](https://fortune.com/2025/04/11/albert-saniger-nate-shopping-app-fraud-ai-justice-department/) / [2](https://theoutline.com/post/2520/strangers-are-looking-at-your-data-for-pennies) / [3](https://www.cnbc.com/2018/01/08/facebook-is-shutting-down-m.html) / [4](https://www.businessinsider.com/amazons-just-walk-out-actually-1-000-people-in-india-2024-4) / [5](https://techcrunch.com/2018/05/10/duplex-shows-google-failing-at-ethical-and-creative-ai-design/) / [6](https://time.com/6247678/openai-chatgpt-kenya-workers/)
[^intelligence]: Yes there will always be new ideas and smart people. But it might be in spite of AI and not thanks to it, in the same way that some people are still very good at mental arithmetics in spite of the calculator everyone has on their phone.