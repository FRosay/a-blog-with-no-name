+++
title = "I am not anti-AI, it's AI that is anti-me"
date = '2026-02-01T19:00:00+01:00'
draft = true
+++

> Foreword: this article probably doesn't reflect what I think very well, or at least it doesn't reflect the entirety of what I think. Yet here it is, as a snapshot of my current thoughts. Although I don't believe I will disown them very soon - if ever -, they will probably keep evolving. Please keep this in mind while reading.

The title of this article may look like a joke to you, but know that it is, in fact, not a joke. It is merely a way to somewhat summarize what would have been an honest title[^title]

However, it probably warrants some precisions before we really get going.
So let's just say that when the title says "AI", it actually means the current batch of "generative AI": [LLMs](https://en.wikipedia.org/wiki/Large_language_model) (Large Language Models, like ChatGPT). Let's also say that, because AI[^AI] doesn't have a conscience and is incapable of reasoning, it can't be "anti" anything. Lastly, please know that I do not think so highly of myself that I would believe that an AI - even an actually intelligent one - could be anti "me" personally. But I do believe that AI poses significant problems, problems we should be solving _before_ we use try push AI into every part of everyone's life.

## AI's biggest problem is that it has so many

It is immediately clear, when taking a critical look at AI, that it has many negative impacts on many different areas of many different people's life. The most discussed of those problems are probably it's ecological impact[^ecology], the fact that it replaces or devalues certain jobs, and the general plundering of data, with no respect for copyright or privacy, that sustains it. One might also think about the current debate on wether LLMs actually make us more productive or not, the fact that the whole industry was mostly built on lies[^lies], or the long-term risks on our ability to learn that AI poses, among other topics. Yet as interesting and valid as all of those subjects are, I would like to touch on a slighly different one.

As someone who regularly tries to discuss AI[^discuss] with any and all people who are willing to, I can't help but feel that most people who use LLMs mostly know about all the problems mentioned above. It just isn't enough to stop them from using their favorite chatbot. Why is that? Are we so used to hearing about our negative ecological impact that it 



Car, en discutant régulièrement du sujet, j'ai l'impression que la plupart des personnes qui utilisent l'IA ont tout à fait conscience, au fond, de la plupart de ces problèmes. Cela ne suffit juste pas à les empêcher de se servir de leur LLM favori. Pourquoi ? Est-ce que nous avons été collectivement habitués à entendre que nos comportements nuisaient à l'écologie, au point de nous désensibiliser du sujet ? Est-ce qu'encore une fois, ce qui se déroule ailleurs que littéralement sous nos yeux est trop difficile à appréhender ? Est-ce que l'espoir de gains personnels fabuleux éclipse tout sentiment moral ?

La question est probablement aussi complexe du point de vue individuel qu'elle est triviale en ce qui concerne les entreprises, pour qui seul le profit - ou son potentiel, ce qui est très différent - est l'alpha et l'omega de l'existence. Pourtant, ce sont souvent les mêmes explications qui reviennent pour justifier l'utilisation de l'IA.

## Dépasser les lieux communs dépolitisants

A chaque discussion informelle sur le sujet de l'IA, deux sujets reviennent, je crois, assez systématiquement. Deux petites phrases qui semblent anodines, mais qui émoussent immédiatement les velléités d'esprit critique. La première nous explique que l'IA n'est "que" un outil, dont il faut apprendre à se servir correctement. La seconde assène plus ou moins durement que "de toute façon, l'IA est là" et qu'il faudrait donc absolument s'adapter. Je crois, pour ma part, que ces deux voies sont des impasses intellectuelles.

### Voir plus loin que le bout de ses outils

Que dit-on (peut-être malgré soi) quand on dit que l'IA n'est qu'un outil ? Que met-on de côté ? D'abord, on écarte tout ce qui était nécessaire pour faire exister l'outil. On évite de penser à la façon dont il a été créé, avec quels matériaux, dans quel contexte politique, etc. Pour l'IA, cela revient à refuser d'évoquer toute une chaîne de production qui va de la récolte de métaux rares dans des conditions dramatiques jusqu'au pillage généralisé de nos données, notamment toutes les œuvres artistiques postées un jour sur internet.

Même en ignorant l'existence qu'un outil a pu avoir avant d'être utilisé pour la première fois, il reste faux de croire que l'entièreté de la réflexion à avoir à son sujet réside dans l'utilisation que l'on devrait en faire ou non. [Cet article](https://www.frank.computer/blog/2025/05/just-a-tool.html) de Frank Elavsky l'explique bien : un outil est conçu pour certains usages ; il en inhibe d'autres, ou les rend impossibles. Un marteau vous incite à le saisir par le manche et à frapper avec sa tête. L'inverse est possible, mais moins efficace. Un marteau vous oblige également à le balancer d'avant en arrière pour l'utiliser. Se contenter d'appuyer très fort sans mouvement de balancier est probablement encore moins efficace que de le saisir par la tête.

Mais prenons un autre type d'outil sur lequel le questionnement serait plus évidemment radical que pour un marteau : une arme. Une arme n'est pas "juste" un outil. C'est un outil qui tue, qui blesse ou qui mutile. Sans même parler de l'utiliser, le fait de porter une arme est donc quelque chose qu'un certain nombre de personnes, moi-même compris, refuse purement et simplement. C'est même une position morale qui a été suffisamment acceptée pour que des pays entiers mettent en place une alternative civile au service militaire.

On voit là assez clairement que si une telle position morale est possible s'agissant d'un objet aussi bête et méchant qu'une arme à feu, elle doit l'être également dans le cas de l'IA générative, [comme pour toutes les technologies](https://aeon.co/essays/bernard-stieglers-philosophy-on-how-technology-shapes-our-world). Certes, l'IA n'a pas pour objectif avoué de tuer, mais elle n'en fait pas moins tout le mal déjà évoqué plus haut. Malheureusement pour ses défenseurs, [la finalité d'un système est ce qu'il fait](https://fr.wikipedia.org/wiki/Stafford_Beer#POSIWID), et la production la plus commune et reconnue de l'IA est le _[slop](https://fr.wikipedia.org/wiki/Slop_(intelligence_artificielle))_.

### FOMO partout, performances nulle part

Le second sentiment que j'entends trop souvent pour pouvoir l'ignorer s'exprime généralement sous la forme d'un sommaire "de toute façon, l'IA est déjà là". Sous-entendu, tant pis ; puisque les autres le font, alors je vais m'y mettre aussi pour ne pas être laissé sur la touche. Ce sentiment semble exister partout, autant chez les personnes qui n'ont pas vraiment d'avis sur la question que chez celles qui sont, par principe, en faveur de ou opposées à l'IA.

Le camp de l'opposition apparaît souvent poussé par le fatalisme ou la pression (voire l'obligation) extérieure, quand il ne rejoint pas carrément le camp qui est en faveur de l'IA dans une sorte de [syndrome FOMO](https://fr.wikipedia.org/wiki/Syndrome_FOMO) déguisé en pragmatisme de circonstance bien pratique. Le troisième camp, enfin, semble quant à lui suivre une forme de [principe de moindre effort](https://fr.wikipedia.org/wiki/Principe_du_moindre_effort) : puisque tout le monde parle d'IA et puisqu'elle m'évite de devoir faire moi-même mes recherches Google, alors autant l'utiliser.

Dans tous les cas, il semblerait que les personnes qui suivent ces approches acceptent bien plus que la simple _existence_ de l'IA, mais également son _utilité_. Or, il est loin d'être certain que les avantages potentiels des LLMs en vaillent la peine. Et quand bien même ce serait le cas pour certaines personnes ou certaines professions, nous pourrions très bien estimer que le prix à payer collectivement pour le bénéfice de quelques-uns est trop élevé. En effet, ce n'est pas comme si l'IA avait fait la preuve de sa capacité à améliorer notre existence collective.

Concernant les bénéfices des LLMs, rappelons qu'en tant que produit, ils se sont vendus sur certains des plus gros mensonges de la dernière décennie, ce qui est beaucoup dire quand on se souvient que cette dernière a vu passer la blockchain, les NFTs, les cryptomonnaies et le métavers. Pourtant, il suffit de suivre vaguement leur actualité pour constater que les IAs, même dans des domaines où elles peuvent être utiles, sont rarement à la hauteur de leurs promesses. La plupart du temps, [ce ne sont en fait même pas des IAs](https://em360tech.com/tech-articles/why-are-humans-pretending-be-bots-rise-pseudo-ai-tech), [mais](https://www.business-humanrights.org/en/latest-news/philippines-scale-ai-creating-race-to-the-bottom-as-outsourced-workers-face-poor-conditions-in-digital-sweatshops-incl-low-wages-withheld-payments/) [des](https://fortune.com/2025/04/11/albert-saniger-nate-shopping-app-fraud-ai-justice-department/) [êtres](https://theoutline.com/post/2520/strangers-are-looking-at-your-data-for-pennies) [humains](https://www.cnbc.com/2018/01/08/facebook-is-shutting-down-m.html), notamment [en](https://timesofindia.indiatimes.com/technology/tech-news/how-this-billion-dollar-london-startup-backed-by-microsoft-made-700-engineers-sitting-in-india-pose-as-ai/articleshow/121572659.cms) [Inde](https://www.businessinsider.com/amazons-just-walk-out-actually-1-000-people-in-india-2024-4).

Même quand ce sont bel et bien des IAs, il peut être difficile de trouver des sources fiables pour mesurer leurs performances. [Ce post Reddit](https://www.reddit.com/r/ClaudeAI/comments/1mwtyan/are_there_any_real_benchmarks_showing_these_ai/), par exemple, demande simplement des références d'études un peu solides... et la seule qui soit mentionnée en réponse est [la fameuse étude METR](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/) de juillet 2025. Sauf que cette dernière a enregistré une diminution de la productivité de développeurs expérimentés utilisant l'IA, au lieu de l'augmentation attendue.

## Le solutionnisme n'est pas la solution

Un premier réflexe instinctif devant l'ensemble des problèmes soulevés par l'IA, comme devant d'autres d'ailleurs, est de tenter de leur trouver des solutions. Malheureusement, ces dernières dépendront mécaniquement du diagnostic qui aura été posé dans un premier temps. Notamment, le fait d'analyser un problème comme contingent amènera probablement à considérer des solutions du même ordre, au lieu d'y apporter des réponses structurelles. Ces dernières, pourtant, semblent plus que nécessaires dans le cas des LLMs.

En attendant, qui nous dit que nous sommes dans l'obligation d'utiliser une technologie aussi néfaste ? L'argument plaît généralement peu, mais s'engager dans une forme de décroissance technologique ne signifie pas être anti-technologie ou même anti-IA. Questionner et vouloir limiter l'usage généralisé de chatbots sous stéroïdes n'est pas une attaque, mais une défense. Il s'agit de nous protéger, nous humains, des effets sur le climat de l'émergence d'une nouvelle industrie polluante. De s'assurer que nos nouveaux outils ne tendent pas à nous rendre [moins créatifs](https://drive.google.com/file/d/1K3nSFdrKwg4h314skO3kT--Rso3xQ1Dd/view) ou [moins intelligents](https://arxiv.org/abs/2506.08872)[^intelligence] _avant_ de les généraliser, pas après.

"_Move fast and break things_"[^break], officiellement la devise de Facebook jusqu'en 2014, est un objectif entendable lorsqu'il s'agit de développer un site internet rapidement et de corriger ses bugs plus tard. Ce n'est définitivement pas souhaitable lorsque la rapidité consiste à être toujours en avance sur les régulations gouvernementales et que ce sont des vies qui sont brisées. Il n'est pas trop tard pour ralentir, voire faire pause, et choisir consciemment ce dont nous voulons ou non.


[^title]: Such as "Yes I do have some objections to the use of AI, not because I am against technology or a contrarian, but because generative AI such as it exists today is either dangerous or, at best, doing us a disservice", for example.
[^AI]: Yes I will be writing "AI" instead of "generative AI" or "LLMs". Sorry not sorry.
[^ecology]: Yes it has a lower impact than other industries, but that doesn't make it automatically acceptable. It's still an additional weight on our global carbon footprint, which cannot be justified by the only thing it actually mass produces : _[slop](https://en.wikipedia.org/wiki/AI_slop)_.
[^lies]: We'll get back to those.
[^discuss]: Even though I can't really recommend it, to be fair.


[^intelligence]: Oui il y aura toujours des nouvelles idées et des personnes intelligentes. Mais ce sera peut-être malgré l'IA et non grâce à elle, de la même façon qu'il y a toujours aujourd'hui des personnes douées en calcul mental malgré la présence de calculatrices toujours à portée de main sur nos téléphones.
[^break]: Littéralement "_Agir vite et casser des trucs_"