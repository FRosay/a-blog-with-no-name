+++
title = "Ce n'est pas moi qui suis anti-IA, c'est l'IA qui est anti-moi"
date = '2026-01-19T12:00:00+01:00'
draft = true
+++

1 : intro sur IA = problèmes (~OK)
2 : problèmes sont connus et discutés, mais ça n'empêche pas d'utiliser l'IA ; pourquoi ? (~OK sauf titre)
3 : repartir de ce que disent les gens, transition into deux sous-parties (~OK mais titre à trouver)
3.1 : "c'est un outil (comme un autre)" ; en fait non (à relire / corriger + intégrer les liens dans le texte + titre bof)
3.2 : "de toute façon c'est là" ; ce n'est pas une raison
4 : insister sur l'absence de preuves suffisantes de l'IA comme améliorateur de performances
5 : conclure sur une position de principe contre le solutionnisme facile et pour des solutions aux causes, pas aux effets

Le titre de cet article peut ressembler à une blague, mais soyez prévenus qu'il n'en est rien. S'il a cette tournure, c'était seulement qu'il aurait été trop long d'écrire un titre honnête[^title].

En revanche, il vrai que ce titre nécessite probablement quelques précisions avant de rentrer dans le vif du sujet.
Précisons donc d'abord que l'IA, ici, est évidemment entendue comme comprenant uniquement l'IA dite "générative", et seulement dans son implémentation courante (les LLMs). Précisons encore que, puisque l'IA[^IA] n'est douée ni de conscience ni de raison, elle ne peut être "anti" quoi que ce soit. Précisons enfin que je ne suis pas présomptueux au point de penser qu'une IA, même intelligente, serait contre "moi" spécifiquement ; mais je crois que l'IA pose des problèmes significatifs qui, tant qu'ils n'auront pas été résolus, devraient nous inciter à restreindre son utilisation.

## Le mystère de l'attrait formidable des IAs génératives

De nombreux problèmes apparaissent très rapidement lorsque l'on s'intéresse à la critique de l'IA. Pour ne citer que les plus en vogue, on pourrait évoquer son impact écologique[^écologie], le fait qu'elle remplacerait ou précariserait certains métiers, ainsi qu'un pillage de données ignorant souvent toute notion de droit d'auteur. On pourrait y ajouter le débat sur l'efficacité réelle des LLMs censés booster notre productivité, le fait que l'industrie se soit largement bâtie sur des mensonges, ou encore les risques à long-terme sur l'apprentissage, entre autres. Mais, aussi valides à soulever que soient chacun de ces points, j'aimerais ici proposer un angle légèrement différent.

Car, en discutant régulièrement du sujet, j'ai l'impression que la plupart des personnes qui utilisent l'IA ont tout à fait conscience, au fond, de la plupart de ces problèmes. Cela ne suffit juste pas à les empêcher de se servir de leur LLM favori. Pourquoi ? Est-ce que nous avons été collectivement habitués à entendre que nos comportements nuisaient à l'écologie, au point de nous désensibiliser du sujet ? Est-ce qu'encore une fois, ce qui se déroule ailleurs que littéralement sous nos yeux est trop difficile à appréhender ? Est-ce que l'espoir de gains personnels fabuleux éclipse tout sentiment moral ?

La question est évidemment aussi complexe du point de vue individuel qu'elle est triviale en ce qui concerne les entreprises, pour qui le profit - ou son potentiel, ce qui est très différent - est l'alpha et l'omega de l'existence.

## Titre à trouver

A chaque discussion sur le sujet de l'IA, deux sujets reviennent, je crois, assez systématiquement. Deux petites phrases qui semblent anodines, mais qui émoussent immédiatement les velleités d'esprit critique. La première nous explique que l'IA n'est "que" un outil, dont il faut apprendre à se servir correctement. La seconde assène plus ou moins durement que "de toute façon, l'IA est là" et qu'il faudrait donc absolument s'adapter. Je crois, pour ma part, que ces deux voies sont des impasses intellectuelles.

### De l'incapacité à penser les outils

Que dit-on (peut-être malgré soi) quand on dit que l'IA n'est qu'un outil ? Que met-on de côté ? D'abord, on écarte tout ce qui était nécessaire pour faire exister l'outil. On évite de penser à la façon dont il a été créé, avec quels matériaux, dans quel contexte politique, etc. Pour l'IA, cela revient à refuser d'évoquer toute une chaîne de production qui va de la récolte de métaux rares dans des conditions dramatiques jusqu'au pillage généralisé de nos données, notamment toutes les oeuvres artistiques postées un jour sur internet.

Même en ignorant l'existence qu'un outil a pu avoir avant d'être utilisé pour la première fois, il reste faux de croire que l'entièreté de la réflexion à avoir à son sujet réside dans l'utilisation que l'on devrait en faire ou non. Car un outil est conçu pour certains usages ; il en inhibe d'autres, ou les rend impossibles. Un marteau vous incite à le saisir par le manche et à frapper avec sa tête. L'inverse est possible, mais moins efficace. Un marteau vous oblige également à le balancer d'avant en arrière pour l'utiliser. Se contenter d'appuyer très fort sans mouvement de balancier est probablement encore moins efficace que de le saisir par la tête.

Mais prenons un autre type d'outil sur lequel le questionnement serait plus évidemment radical que pour un marteau : les armes. Une arme n'est pas "juste" un outil. C'est un outil qui tue, qui blesse ou qui mutile. Sans même parler de l'utiliser, le fait de porter une arme est donc quelque chose qu'un certain nombre de personnes, moi-même compris, refuse purement et simplement. C'est même une position morale qui a été suffisamment acceptée pour que des pays entiers mettent en place une alternative civile au service militaire.

On voit là assez clairement que si une telle position morale est possible s'agissant d'un objet aussi bête et méchant qu'une arme à feu, elle doit l'être également dans le cas de l'IA générative. Certes, cette dernière n'a pas pour objectif avoué de tuer, mais elle n'en fait pas moins tout le mal déjà évoqué plus haut. Malheureusement pour ses défenseurs, [la finalité d'un système est ce qu'il fait](https://fr.wikipedia.org/wiki/Stafford_Beer#POSIWID), et la production la plus commune et reconnue de l'IA est le _[slop](https://fr.wikipedia.org/wiki/Slop_(intelligence_artificielle))_.

J'en finirai ici en recommandant fortement deux articles (en anglais) sur le sujet, l'un de [Frank Elavsky](https://www.frank.computer/blog/2025/05/just-a-tool.html) sur précisément l'erreur de penser que quelque chose puisse n'être qu'un outil, et [l'autre](https://aeon.co/essays/bernard-stieglers-philosophy-on-how-technology-shapes-our-world) plus général sur la philosophie de [Bernard Stiegler](https://fr.wikipedia.org/wiki/Bernard_Stiegler), philosophe de la technique.

### FOMO partout, justice nulle part

Le second sentiment que j'entends trop souvent pour pouvoir l'ignorer s'exprime généralement sous la forme d'un somamire "de toute façon, l'IA est déjà là". Sous-entendu, tant pis ; puisque les autres le font, alors je vais m'y mettre aussi pour ne pas être laissé sur la touche. Ce sentiment semble toucher aussi bien les personnes qui n'ont pas vraiment d'avis sur la question que celles qui sont par principe opposées à l'IA. Mais, là où ces dernières m'apparaissent poussées par le fatalisme, les autres font à mon goût trop montre d'une sorte de [syndrome FOMO](https://fr.wikipedia.org/wiki/Syndrome_FOMO) déguisé en pragmatisme de circonstance bien pratique.

Dans les deux cas, il semblerait que les personnes qui suivent cette approche acceptent bien plus que la simple _existence_ de l'IA, mais également son _utilité_. Or, il est loin d'être certain que les avantages potentiels[^avantages] des LLMs en vaillent la peine. Quand bien même ce serait le cas pour certaines personnes ou certaines professions, nous pourrions très bien estimer que le prix à payer collectivement pour le bénéfice de quelques-uns est trop élevé. En effet ce n'est pas comme si l'IA avait fait la preuve de sa capacité à améliorer notre existence.

Cette façon de faire face à l'IA en ignore ou en minimise donc les coûts cachés, tout en surestimant les avantages à en retirer.

## L'IA au beau pays de la théorie

L'IA, en tant que produit, s'est vendue sur certains des plus gros mensonges de la dernière décennie, ce qui est beaucoup dire quand on se souvient que cette dernière a vu passer la blockchain, les NFTs et le métavers. Pourtant, il suffit de suivre vaguement leur actualité pour constater que les IAs, même dans des domaines où elles peuvent être utiles, ne sont jamais à la hauteur de leurs promesses. La plupart du temps, ce n'est en fait pas une IA du tout mais des [êtres](https://theoutline.com/post/2520/strangers-are-looking-at-your-data-for-pennies) [humains](https://www.cnbc.com/2018/01/08/facebook-is-shutting-down-m.html), notamment [en](https://timesofindia.indiatimes.com/technology/tech-news/how-this-billion-dollar-london-startup-backed-by-microsoft-made-700-engineers-sitting-in-india-pose-as-ai/articleshow/121572659.cms) [Inde](https://www.businessinsider.com/amazons-just-walk-out-actually-1-000-people-in-india-2024-4). Et quand ce sont bel et bien des IAs, il peut être difficile de trouver des sources fiables pour mesurer leurs performances. [Ce post Reddit](https://www.reddit.com/r/ClaudeAI/comments/1mwtyan/are_there_any_real_benchmarks_showing_these_ai/), par exemple, demande simplement des références d'études un peu solides... et la seule qui soit mentionnée en réponse est la fameuse étude

## Le solutionnisme n'est pas la solution

Que faire une fois que l'on a établi notre propre incapacité morale à accepter

Problèmes de beaucoup de critiques tièdes : proposer des solutions tièdes, par exemple des pratiques ponctuelles, comme si elles pouvaient contrecarrer la force globale des outils.



[^title]: Tel que "Oui j'ai des objections à l'utilisation de LLMs mais pas par anti-technologisme primaire ou esprit de contradiction, juste parce que l'IA générative telle qu'elle existe aujourd'hui nous nuit collectivement de plusieurs façons", par exemple.
[^IA]: Oui je vais reprendre le language courant et dire "IA" pour "IA générative" ou "LLM". Déso pas déso.
[^écologie]: Dont je ne peux pas m'empêcher de dire deux mots : ce n'est pas parce que son impact est moindre que d'autres industries qu'il est automatiquement acceptable. C'est un poids supplémentaire sur notre empreinte environnementale, poids qui ne saurait être justifié par la seule chose que l'IA sait produire en masse de façon fiable : le _[slop](https://fr.wikipedia.org/wiki/Slop_(intelligence_artificielle))_.
[^avantages]: On y reviendra.