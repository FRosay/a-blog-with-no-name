+++
title = "Ce n'est pas moi qui suis anti-IA, c'est l'IA qui est anti-moi"
date = '2026-01-19T12:00:00+01:00'
draft = true
+++

## 1 : IA = problèmes (~OK)
## 2 : problèmes sont connus et discutés, mais ça n'empêche pas d'utiliser l'IA ; pourquoi ? (~OK sauf titre)
## 3 : repartir de ce que disent les gens, comme "c'est un outil (comme un autre)" ; en fait non
## 4 : les gens disent aussi souvent que "de toute façon c'est là" ; ce n'est pas une raison
## 5 : insister sur l'absence de preuves suffisantes de l'IA comme améliorateur de performances
## 6 : conclure sur une position de principe contre le solutionnisme facile et pour des solutions aux causes, pas aux effets

Le titre de cet article peut ressembler à une blague, mais soyez prévenus qu'il n'en est rien. S'il a cette tournure, c'était seulement qu'il aurait été trop long d'écrire un titre honnête[^title].

En revanche, il vrai que ce titre nécessite probablement quelques précisions avant de rentrer dans le vif du sujet.
Précisons donc d'abord que l'IA, ici, est évidemment entendue comme comprenant uniquement l'IA dite "générative", et seulement dans son implémentation courante (les LLMs). Précisons encore que, puisque l'IA[^IA] n'est douée ni de conscience ni de raison, elle ne peut être "anti" quoi que ce soit. Précisons enfin que je ne suis pas présomptueux au point de penser qu'une IA, même intelligente, serait contre "moi" spécifiquement ; mais je crois que l'IA pose des problèmes significatifs qui, tant qu'ils n'auront pas été résolus, devraient nous inciter à restreindre son utilisation.

## Le mystère de l'attrait formidable des IAs génératives

De nombreux problèmes apparaissent très rapidement lorsque l'on s'intéresse à la critique de l'IA. Pour ne citer que les plus en vogue, on pourrait évoquer son impact écologique[^écologie], le fait qu'elle remplacerait ou précariserait certains métiers, ainsi qu'un pillage de données ignorant souvent toute notion de droit d'auteur. On pourrait y ajouter le débat sur l'efficacité réelle des LLMs censés booster notre productivité, le fait que l'industrie se soit largement bâtie sur des mensonges, ou encore les risques à long-terme sur l'apprentissage, entre autres. Mais, aussi valides à soulever que soient chacun de ces points, j'aimerais ici proposer un angle légèrement différent.

Car, en discutant régulièrement du sujet, j'ai l'impression que la plupart des personnes qui utilisent l'IA ont tout à fait conscience, au fond, de la plupart de ces problèmes. Cela ne suffit juste pas à les empêcher de se servir de leur LLM favori. Pourquoi ? Est-ce que nous avons été collectivement habitués à entendre que nos comportements nuisaient à l'écologie, au point de nous désensibiliser du sujet ? Est-ce qu'encore une fois, ce qui se déroule ailleurs que littéralement sous nos yeux est trop difficile à appréhender ? Est-ce que l'espoir de gains personnels fabuleux éclipse tout sentiment moral ?

La question est évidemment aussi complexe du point de vue individuel qu'elle est triviale en ce qui concerne les entreprises, pour qui le profit - ou son potentiel, ce qui est très différent - est l'alpha et l'omega de l'existence.

## De l'incapacité à penser les outils

A chaque discussion sur le sujet de l'IA, deux sujets reviennent, je crois, assez systématiquement. Deux petites phrases  

## FOMO partout, justice nulle part

Dans mes discussions, un sentiment que j'entends trop souvent pour ignorer s'exprime souvent sous la forme d'un "de toute façon, l'IA est déjà là". Sous-entendu, tant pis ; puisque les autres le font, alors je vais m'y mettre aussi pour ne pas être laissé sur la touche. Ce sentiment semble toucher aussi bien les personnes qui n'ont pas vraiment d'avis sur la question que celles qui sont par principe opposées à l'IA. Ces dernières semblent poussées par un fatalisme du à l'absence d'alternatives, tandis que les premières font souvent montre d'une sorte de [syndrome FOMO](https://fr.wikipedia.org/wiki/Syndrome_FOMO) déguisé en pragmatisme de circonstance bien pratique.

Quoi qu'il en soit, cette approche accepte bien plus que la simple _existence_ de l'IA, mais également une _utilité_ de l'IA si importante qu'elle éclipse toute autre considération. Or, il est loin d'être certain que les avantages potentiels[^avantages] des LLMs en vaillent la peine. Et puis, quand bien même ce serait le cas pour certaines personnes, nous pourrions très bien estimer que le prix à payer collectivement pour l'avantage de quelques-uns est trop élevé.

Cette façon de faire face à l'IA en ignore ou en minimise donc les coûts cachés, mais a aussi souvent un autre problème majeur : elle en surestime les avantages.

## L'IA au beau pays de la théorie

L'IA, en tant que produit, s'est vendue sur certains des plus gros mensonges de la dernière décennie, ce qui est beaucoup dire quand on se souvient que cette dernière a vu passer la blockchain, les NFTs et le métavers. Pourtant, il suffit de suivre vaguement leur actualité pour constater que les IAs, même dans des domaines où elles peuvent être utiles, ne sont jamais à la hauteur de leurs promesses. La plupart du temps, ce n'est en fait pas une IA du tout mais des [êtres](https://theoutline.com/post/2520/strangers-are-looking-at-your-data-for-pennies) [humains](https://www.cnbc.com/2018/01/08/facebook-is-shutting-down-m.html), notamment [en](https://timesofindia.indiatimes.com/technology/tech-news/how-this-billion-dollar-london-startup-backed-by-microsoft-made-700-engineers-sitting-in-india-pose-as-ai/articleshow/121572659.cms) [Inde](https://www.businessinsider.com/amazons-just-walk-out-actually-1-000-people-in-india-2024-4). Et quand ce sont bel et bien des IAs, il peut être difficile de trouver des sources fiables pour mesurer leurs performances. [Ce post Reddit](https://www.reddit.com/r/ClaudeAI/comments/1mwtyan/are_there_any_real_benchmarks_showing_these_ai/), par exemple, demande simplement des références d'études un peu solides... et la seule qui soit mentionnée en réponse est la fameuse étude

## Le solutionnisme n'est pas la solution

Que faire une fois que l'on a établi notre propre incapacité morale à accepter

Problèmes de beaucoup de critiques tièdes : proposer des solutions tièdes, par exemple des pratiques ponctuelles, comme si elles pouvaient contrecarrer la force globale des outils.



[^title]: Tel que "Oui j'ai des objections à l'utilisation de LLMs mais pas par anti-technologisme primaire ou esprit de contradiction, juste parce que l'IA générative telle qu'elle existe aujourd'hui nous nuit collectivement de plusieurs façons", par exemple.
[^IA]: Oui je vais reprendre le language courant et dire "IA" pour "IA générative" ou "LLM". Déso pas déso.
[^écologie]: Dont je ne peux pas m'empêcher de dire deux mots : ce n'est pas parce que son impact est moindre que d'autres industries qu'il est automatiquement acceptable. C'est un poids supplémentaire sur notre empreinte environnementale, poids qui ne saurait être justifié par la seule chose que l'IA sait produire en masse de façon fiable : le _[slop](https://fr.wikipedia.org/wiki/Slop_(intelligence_artificielle))_.
[^avantages]: On y reviendra.


---------
Hail the maintainers : https://aeon.co/essays/innovation-is-overvalued-maintenance-often-matters-more
Homogenization effects of large language models on human creative ideation : https://drive.google.com/file/d/1K3nSFdrKwg4h314skO3kT--Rso3xQ1Dd/view
Apple skips AI race : https://qz.com/apple-intelligence-ai-apps-chips-iphones
Everyone hates Copilot : https://qz.com/microsoft-copilot-rage

WIP

AI is not just a tool: 
- https://www.frank.computer/blog/2025/05/just-a-tool.html
- https://aeon.co/essays/bernard-stieglers-philosophy-on-how-technology-shapes-our-world


Ecology:
- Powered by natural gas plane engine turbines:
-- https://techcrunch.com/2025/12/09/boom-supersonic-raises-300m-to-build-natural-gas-turbines-for-crusoe-data-centers/
-- https://www.tomshardware.com/tech-industry/data-centers-turn-to-ex-airliner-engines-as-ai-power-crunch-bites
-- https://www.politico.com/news/2025/05/06/elon-musk-xai-memphis-gas-turbines-air-pollution-permits-00317582

- And coal:
-- https://www.washingtonpost.com/business/interactive/2024/data-centers-internet-power-source-coal/

- Obviously slowing the reduction in emissions:
-- https://www.bloomberg.com/news/articles/2024-07-23/ai-boom-to-slow-pace-of-us-emissions-reduction-report-says
-- https://www.nationalobserver.com/2025/09/04/investigations/google-net-zero-sustainability
-- https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/

- And draining water:
-- https://www.cnbc.com/2025/10/16/water-ai-mega-projects-raise-alarm-in-some-of-europes-driest-regions.html


Les benchmarks d'IA ne valent pas grand-chose :
- https://www.theregister.com/2025/11/07/measuring_ai_models_hampered_by/
- https://arxiv.org/pdf/2411.12990
- https://arxiv.org/abs/2502.06559
- https://www.lesswrong.com/posts/cu2E8wgmbdZbqeWqb/meemi-s-shortform


Souvent, l'IA est soit un mensonge (il y a des humains derrière), soit entraînée et monitorée par des humains de toute façon, et généralement dans des conditions indignes :
- Builder.ai : https://timesofindia.indiatimes.com/technology/tech-news/how-this-billion-dollar-london-startup-backed-by-microsoft-made-700-engineers-sitting-in-india-pose-as-ai/articleshow/121572659.cms
- Nate : https://fortune.com/2025/04/11/albert-saniger-nate-shopping-app-fraud-ai-justice-department/
- Amazon Just Walk Out : https://www.businessinsider.com/amazons-just-walk-out-actually-1-000-people-in-india-2024-4
- Expensify : https://theoutline.com/post/2520/strangers-are-looking-at-your-data-for-pennies
- Scale AI : https://www.business-humanrights.org/en/latest-news/philippines-scale-ai-creating-race-to-the-bottom-as-outsourced-workers-face-poor-conditions-in-digital-sweatshops-incl-low-wages-withheld-payments/
- M (FB Messenger assistant) : https://www.cnbc.com/2018/01/08/facebook-is-shutting-down-m.html
- Applis de lecture de reçus : https://theoutline.com/post/2520/strangers-are-looking-at-your-data-for-pennies
- Theranos : https://en.wikipedia.org/wiki/Theranos?trk=article-ssr-frontend-pulse_little-text-block
- Google Duplex : https://techcrunch.com/2018/05/10/duplex-shows-google-failing-at-ethical-and-creative-ai-design/
- OpenAI & kenyan workers : https://time.com/6247678/openai-chatgpt-kenya-workers/
- In general : https://em360tech.com/tech-articles/why-are-humans-pretending-be-bots-rise-pseudo-ai-tech


- Utilisations dans des affaires judiciaires :
-- https://www.damiencharlotin.com/hallucinations/

- Faux clients ou succès pour des entreprises :
-- https://techcrunch.com/2025/03/24/a16z-and-benchmark-backed-11x-has-been-claiming-customers-it-doesnt-have/

- Fausse intelligence de l'IA :
-- https://softwarecrisis.dev/letters/llmentalist/

- L'IA ne synthétise pas, elle raccourcit :
-- https://www.crikey.com.au/2024/09/03/ai-worse-summarising-information-humans-government-trial/
-- https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/

- Problèmes de sécurité très graves :
-- https://www.aim.security/post/when-public-prompts-turn-into-local-shells-rce-in-cursor-via-mcp-auto-start
-- https://www.aim.security/post/echoleak-blogpost


Effets psycho-sociaux pervers :
- Perte d'agentivité par la délégation totale de navigation / réflexion / etc :
-- https://www.doc.cc/articles/ai-navigation

- Fake News :
-- https://www.bbc.co.uk/mediacentre/2025/new-ebu-research-ai-assistants-news-content
-- https://www.theverge.com/ai-artificial-intelligence/835839/google-discover-ai-headlines-clickbait-nonsense
-- https://www.theverge.com/2024/11/12/24289939/apple-intelligence-ai-notification-summaries-awkward-funny-bad
-- https://www.wsj.com/tech/elon-musks-grok-chatbot-publishes-series-of-antisemitic-posts-2a41e67e?mod=article_inline
-- https://chicago.suntimes.com/news/2025/05/20/syndicated-content-sunday-print-sun-times-ai-misinformation
-- https://themarkup.org/news/2024/03/29/nycs-ai-chatbot-tells-businesses-to-break-the-law
-- https://storage.courtlistener.com/recap/gov.uscourts.nysd.575368/gov.uscourts.nysd.575368.31.0.pdf


Problème des données personnelles :
- AI browsers:
-- https://vivaldi.com/blog/a-i-browsers-the-price-of-admission-is-too-high/

- Robots.txt
-- https://www.heise.de/en/background/Obituary-Farewell-to-robots-txt-1994-2025-10766991.html?seite=all


Les vendeurs et utilisateurs d'IA sont englués dans les affaires judiciaires :
- https://githubcopilotlitigation.com/
- https://www.understandingai.org/p/copyright-lawsuits-pose-a-serious
- https://www.plagiarismtoday.com/2023/01/17/the-wave-of-ai-lawsuits-have-begun/
- https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit
- https://www.gtlaw.com/en/insights/2023/8/eeoc-secures-first-workplace-artificial-intelligence-settlement
- https://decisions.civilresolutionbc.ca/crt/crtd/en/item/525448/index.do


Même pas capables d'apporter de vraies améliorations aux métiers impactés :
- Informatique :
-- https://softwarecrisis.dev/letters/ai-and-software-quality/
-- https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/
-- https://cybernews.com/ai-news/replit-ai-vive-code-rogue/


"
A core aspect of the theory-building model of software development is code that developers don’t understand is a liability. It means your mental model of the software is inaccurate which will lead you to create bugs as you modify it or add other components that interact with pieces you don’t understand.

Language model tools for software development are specifically designed to create large volumes of code that the programmer doesn’t understand. They are liability engines for all but the most experienced developer. You can’t solve this problem by having the “AI” understand the codebase and how its various components interact with each other because a language model isn’t a mind. It can’t have a mental model of anything. It only works through correlation.
"

https://www.frank.computer/blog/2024/06/llms-and-thoughts.html
"
But I don’t like management. And LLMs don’t just convert work into management, they convert art into management. They convert thinking anything at all into thinking about management. They convert a love of a craft into managing a machine. They boil down all the passion and frustration and struggle and joy of creation into tasks that a perfectly vibeless worker completes on your behalf. It’s the singularity that capitalism fantasizes about: everyone becomes their own boss of a labor force that never complains. The only thing that matters is whether the outcome of the process works or not.

[...]

This feral, meteoric rise in popularity for LLMs and generative models is really due to an underlying, massively repressed cultural bedrock beneath a handful of people in the tech world. These dreamers believe in their bones that they should have already become billionaires, but simply never got the break they deserved. And no billionaire ever made billions off of their own labor. Being a billionaire is only possible by profiting off of someone else’s work. And LLMs offer to deliver this fantasy that so many petite capitalists have delusions about. LLMs are popular because of a wider cultural obsession with capitalistic vibes.
"

https://www.anildash.com/2025/04/29/ai-first-is-the-new-return-to-office/
"
[...] did your boss ever have to send you a memo demanding that you use a smartphone? Was there a performance review requiring you to use Slack? I'm actually old enough that I was at different workplaces when they started using spreadsheets and email and the web, and I can tell you, they absolutely didn't have to drive adoption by making people fill out paperwork about how they were definitely using the cool new technology. Isn't that interesting?
[...]
It's telling that the creators of so many of the AI tools don't even have enough confidence in their offerings to simply let users choose to adopt them, and are instead forcing them into users' faces in every possible corner of their apps and websites.
[...]
If you think your workers and colleagues are too stupid to recognize good tools that will help them do their jobs better, then... you are a bad leader and should step down. Because you've created a broken culture.
"